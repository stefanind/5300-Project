{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f3c63f0-03dc-41eb-ad2f-be3447e4b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm, ttest_ind, stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dcea84d-0571-439f-a247-5330a620db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_file = pd.read_csv(\"C:\\\\Users\\\\Savannah Truluck\\\\DATA 5300\\\\Final Project\\\\order_file.csv\")\n",
    "penalty_file = pd.read_csv(\"C:\\\\Users\\\\Savannah Truluck\\\\DATA 5300\\\\Final Project\\\\penalty_file.csv\")\n",
    "\n",
    "data = pd.merge(order_file, penalty_file, on=\"driver.id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cdb74b4-4d17-4a21-8aa5-452e07d2f471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8109388665512268, 0.8131705269975439)\n",
      "(-0.03570699473884643, -0.03266887578989185)\n",
      "(-0.05485176258028372, -0.0521579578967178)\n"
     ]
    }
   ],
   "source": [
    "# Number of successes in group 0\n",
    "x0 = data[(data['penalty.variant'] == 0) & (data['cancel.dummy'] == 0)].shape[0]  \n",
    "# Total number of observations in group 0\n",
    "n0 = data[data['penalty.variant'] == 0].shape[0]  \n",
    "# Number of successes in group 10\n",
    "x10 = data[(data['penalty.variant'] == 10) & (data['cancel.dummy'] == 0)].shape[0]  \n",
    "# Total number of observations in group 10\n",
    "n10 = data[data['penalty.variant'] == 10].shape[0]  \n",
    "# Number of successes in group 20\n",
    "x20 = data[(data['penalty.variant'] == 20) & (data['cancel.dummy'] == 0)].shape[0]  \n",
    "# Total number of observations in group 20\n",
    "n20 = data[data['penalty.variant'] == 20].shape[0]  \n",
    "\n",
    "# Proportions\n",
    "p0 = x0 / n0\n",
    "p10 = x10 / n10\n",
    "p20 = x20 / n20\n",
    "\n",
    "# Wald Method\n",
    "# Difference in proportions\n",
    "diff_010 = p0 - p10\n",
    "diff_1020 = p10 - p20\n",
    "\n",
    "# Standard error for the Wald method\n",
    "se_wald_010 = np.sqrt((p0 * (1 - p0) / n0) + (p10 * (1 - p10) / n10))\n",
    "se_wald_1020 = np.sqrt((p10 * (1 - p10) / n10) + (p20 * (1 - p20) / n20))\n",
    "\n",
    "# Wald confidence interval\n",
    "z = norm.ppf(0.975)  # 95% CI\n",
    "wald_ci_0 = (p0 - z * se_wald_0, p0 + z * se_wald_0)\n",
    "wald_ci_010 = (diff_010 - z * se_wald_010, diff_010 + z * se_wald_010)\n",
    "wald_ci_1020 = (diff_1020 - z * se_wald_1020, diff_1020 + z * se_wald_1020)\n",
    "\n",
    "print(wald_ci_010)\n",
    "print(wald_ci_1020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927d861f-db2a-404a-bd8d-f5829af837a9",
   "metadata": {},
   "source": [
    "Confidence Intervals for groups 0 & 10, and groups 10 & 20:\n",
    "\n",
    "(-0.03570699473884643, -0.03266887578989185)\n",
    "\n",
    "(-0.05485176258028372, -0.0521579578967178)\n",
    "\n",
    "These confidence intervals don't include 0 which implies that there is a statistically significant effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfe159b9-75ae-4430-8a3f-88c42978ae66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.94651702e-01, 1.95633469e-03, 4.27998865e-03, 3.32477632e-01,\n",
       "       8.32362470e-06, 3.46634091e-08])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grouping data by penalty and cancellation\n",
    "data_changed = data.copy()\n",
    "data_changed.loc[(data['cancel.dummy'] == 1) & (data['penalty.variant'] == 0), 'expected.profit'] = 0\n",
    "data_changed.loc[(data['cancel.dummy'] == 1) & (data['penalty.variant'] == 10), 'expected.profit'] = 10\n",
    "data_changed.loc[(data['cancel.dummy'] == 1) & (data['penalty.variant'] == 20), 'expected.profit'] = 20\n",
    "\n",
    "data_changed = data_changed.dropna()\n",
    "\n",
    "completed_rides = data[data['cancel.dummy'] == 0]\n",
    "\n",
    "# P-Values\n",
    "# mu0 = mu10 vs mu0 != mu10\n",
    "p1 = ttest_ind(data_changed[data_changed['penalty.variant'] == 0]['expected.profit'],\n",
    "                data_changed[data_changed['penalty.variant'] == 10]['expected.profit']).pvalue\n",
    "# mu0 = mu20 vs mu0 != mu20\n",
    "p2 = ttest_ind(data_changed[data_changed['penalty.variant'] == 0]['expected.profit'],\n",
    "                data_changed[data_changed['penalty.variant'] == 20]['expected.profit']).pvalue\n",
    "# mu20 = mu10 vs mu20 != mu10\n",
    "p3 = ttest_ind(data_changed[data_changed['penalty.variant'] == 20]['expected.profit'],\n",
    "                data_changed[data_changed['penalty.variant'] == 10]['expected.profit']).pvalue\n",
    "\n",
    "rides_per_customer = completed_rides.groupby(['driver.id', 'penalty.variant']).size().reset_index(name='completed_rides')\n",
    "\n",
    "rides_pen0 = rides_per_customer[rides_per_customer['penalty.variant'] == 0]['completed_rides']\n",
    "rides_pen10 = rides_per_customer[rides_per_customer['penalty.variant'] == 10]['completed_rides']\n",
    "rides_pen20 = rides_per_customer[rides_per_customer['penalty.variant'] == 20]['completed_rides']\n",
    "\n",
    "# d0 = d10 vs d0 != d10\n",
    "p4 = ttest_ind(rides_pen0, rides_pen10).pvalue\n",
    "# d0 = d20 vs d0 != d20\n",
    "p5 = ttest_ind(rides_pen0, rides_pen20).pvalue\n",
    "# d20 = d10 vs d20 != d10\n",
    "p6 = ttest_ind(rides_pen20, rides_pen10).pvalue\n",
    "\n",
    "p = np.array([p1, p2, p3, p4, p5, p6])\n",
    "\n",
    "# Adjust p-values\n",
    "p_adjusted = multipletests(p, method='fdr_by')[1]\n",
    "\n",
    "# Results\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512fbad5-d5c2-4976-84ca-6aa718470d0b",
   "metadata": {},
   "source": [
    "The p-values returned are:\n",
    "1.00000000e+00, 9.58603996e-03, 1.57289583e-02 \n",
    "9.77484239e-01, 6.11786415e-05, 5.09552113e-07\n",
    "\n",
    "The first three refer to the expected profit per penalty variant. The first being between 0 & 10, then 0 & 20, and 20 & 10.\n",
    "The second three refer to the completed rides per penalty variant, in the same order of penalty comparisons as the first three tests.\n",
    "\n",
    "This shows us that there is no significant difference for expected profit for penalty groups 0 & 10, although there is a difference between 0 & 20, and 20 & 10.\n",
    "\n",
    "In terms of completed rides, we see no significant difference for completed rides per penalty variant in groups 0 & 10, although we do see a difference between groups 0 & 20, and groups 20 & 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaaddc1-7cb5-46ce-a745-d2d587839959",
   "metadata": {},
   "source": [
    "Cancellation Cost Impact will show us whether there is a significant amount of money lost based on the lost revenue due to cancellations. We will look at each group, calculate (cancellations * expected profit) - (cancellations * penalty) as we only want to look at what we would have gained if the order had gone through and factor out what was gained by the penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d63726-a6d4-4ee5-a6e3-dc060f43d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_impact_alt = data.groupby('driver.id').agg(\n",
    "    cancellations=('cancel.dummy', 'sum'),\n",
    "    expected_profit=pd.NamedAgg(\n",
    "        column='expected.profit',\n",
    "        aggfunc=lambda x: np.sum(x * data.loc[x.index, 'cancel.dummy'])\n",
    "    ),\n",
    "    penalty_paid=pd.NamedAgg(\n",
    "        column='penalty.variant',\n",
    "        aggfunc=lambda x: np.sum(x * data.loc[x.index, 'cancel.dummy'])\n",
    "    )\n",
    ")\n",
    "\n",
    "cost_impact_alt['cancellation_cost_impact'] = (\n",
    "    cost_impact_alt['expected_profit'] - cost_impact_alt['penalty_paid']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ff87c1-08f7-4742-a4d6-d983313b3527",
   "metadata": {},
   "source": [
    "I saved this output as a csv so that I wouldn't have to do the lengthy reprocessing each time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8072f9ae-885a-4830-8044-0a6247db3fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7475632007185573, 3.1564385182070245e-05, 6.2251140865013245e-06]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_impact = pd.read_csv(\"C:\\\\Users\\\\Savannah Truluck\\\\DATA 5300\\\\Final Project\\\\costimpact.csv\")\n",
    "cost_impact = cost_impact.drop(\"Unnamed: 0\", axis = 'columns')\n",
    "cost_impact = cost_impact.dropna(subset=['expected.profit'])\n",
    "\n",
    "# P-Values\n",
    "p7 = ttest_ind(cost_impact['expected.profit'][cost_impact['penalty.variant'] == 0],\n",
    "                     cost_impact['expected.profit'][cost_impact['penalty.variant'] == 10]).pvalue\n",
    "p8 = ttest_ind(cost_impact['expected.profit'][cost_impact['penalty.variant'] == 0],\n",
    "                     cost_impact['expected.profit'][cost_impact['penalty.variant'] == 20]).pvalue\n",
    "p9 = ttest_ind(cost_impact['expected.profit'][cost_impact['penalty.variant'] == 20],\n",
    "                     cost_impact['expected.profit'][cost_impact['penalty.variant'] == 10]).pvalue\n",
    "\n",
    "p = [p7, p8, p9]\n",
    "\n",
    "p_adjusted = multipletests(p, method='bonferroni')[1]\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1aa185-8d83-4d37-9cd2-f1400597eb1b",
   "metadata": {},
   "source": [
    "The p-values returned are: \n",
    "0.7475632007185573, 3.1564385182070245e-05, 6.2251140865013245e-06\n",
    "\n",
    "This shows that there is no significant difference between penalty groups 0 and 10 in terms of cost impact, however, for groups 0/20 and 20/10 we are seeing a statistically significant difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cbd00e8-164f-4d68-8453-3fd1a2158024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:               retained   No. Observations:              1402312\n",
      "Model:                            GLM   Df Residuals:                  1402309\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:            -5.7983e+05\n",
      "Date:                Mon, 02 Dec 2024   Deviance:                   1.1597e+06\n",
      "Time:                        15:26:10   Pearson chi2:                 1.40e+06\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):            0.01020\n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const               1.4588      0.005    268.186      0.000       1.448       1.469\n",
      "penalty.variant     0.0354      0.000    118.268      0.000       0.035       0.036\n",
      "week               -0.0092      0.001     -6.657      0.000      -0.012      -0.006\n",
      "===================================================================================\n"
     ]
    }
   ],
   "source": [
    "#if cancel is 0 then set retained to 1, if it's not 0 set retained to 0\n",
    "data['retained'] = np.where(data['cancel.dummy'] == 0, 1, 0)\n",
    "if data['order.placed.time'].dtype == 'object':\n",
    "    data['order.placed.time'] = pd.to_datetime(data['order.placed.time'].str.replace(' America/Los_Angeles', ''))\n",
    "else:\n",
    "    data['order.placed.time'] = pd.to_datetime(data['order.placed.time'])\n",
    "\n",
    "data['week'] = (data['order.placed.time'] - data['order.placed.time'].min()).dt.total_seconds() / (7 * 24 * 60 * 60)\n",
    "\n",
    "long_term_model = sm.GLM(data['retained'], \n",
    "                        sm.add_constant(data[['penalty.variant', 'week']]), \n",
    "                        family=sm.families.Binomial()).fit()\n",
    "print(long_term_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e04aa5-54b4-47b5-973c-419d8feb3459",
   "metadata": {},
   "source": [
    "This analysis was done for the most basic interpretation of retention, if a ride is canceled then the driver is lost, if they complete the order then they are retained. If we look at the constant coefficient, we get the base log-odds retention when all other variables are 0 which returns as 1.4588. When converted to probability gives us approximately 0.81 or 81% baseline retention. The penalty variant shows that the penalty variant is associated with higher retention and for each unit increase in penalty the log-odds of retention increase 0.0354. However, if we look at week, we see a decrease in retention shown by the -0.0092 log-odds coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "69fbb9ab-7b99-4542-959b-822a86e12126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   mean   No. Observations:               530756\n",
      "Model:                            GLM   Df Residuals:                   530752\n",
      "Model Family:                Binomial   Df Model:                            3\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:            -1.9534e+05\n",
      "Date:                Mon, 25 Nov 2024   Deviance:                   3.4261e+05\n",
      "Time:                        19:37:03   Pearson chi2:                 4.23e+05\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):            0.01112\n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================================\n",
      "                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------\n",
      "const                            1.5889      0.011    149.971      0.000       1.568       1.610\n",
      "('penalty.variant', 'first')     0.0376      0.001     74.295      0.000       0.037       0.039\n",
      "('week', 'min')                  0.0307      0.003     12.071      0.000       0.026       0.036\n",
      "('week', 'max')                 -0.0399      0.003    -15.224      0.000      -0.045      -0.035\n",
      "================================================================================================\n"
     ]
    }
   ],
   "source": [
    "driver_stats = data.groupby('driver.id').agg({\n",
    "    'retained': 'mean', \n",
    "    'penalty.variant': 'first', \n",
    "    'week': ['min', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "driver_model = sm.GLM(\n",
    "    driver_stats['retained'], \n",
    "    sm.add_constant(driver_stats[['penalty.variant', 'week']]),\n",
    "    family=sm.families.Binomial()\n",
    ").fit()\n",
    "\n",
    "print(driver_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccdbd6a-d12c-4e1d-b52b-6766cf562eac",
   "metadata": {},
   "source": [
    "This test analyses a more complex method of checking for retention. For each driver we look at the mean amount of cancellations vs completions. It also looks at their earliest drive and their latest drive to see how long they were driving for.\n",
    "\n",
    "If we look at the constant coefficient, we get the base log-odds retention when all other variables are 0 which returns as 1.5889. When converted to probability gives us approximately 0.83 or 83% baseline retention. The penalty variant coefficient shows that the penalty is associated with higher retention and for each unit increase in penalty the log-odds of retention increase 0.0354. Week minimum shows positive retention for drivers who showed up later in the study period, given by the coefficient value of 0.0307, while drivers who had been driving longer seemed to decline in retention, shown by the negative coefficient value -0.0399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9de2a6-c1f1-46ef-9169-a5ce11ecc87b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
